{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from __future__ import print_function\n",
      "import numpy as np\n",
      "import tensorflow as tf\n",
      "from six.moves import cPickle as pickle\n",
      "from six.moves import range"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pickle_file = 'notMNIST.pickle'\n",
      "\n",
      "with open(pickle_file, 'rb') as f:\n",
      "  save = pickle.load(f)\n",
      "  train_dataset = save['train_dataset']\n",
      "  train_labels = save['train_labels']\n",
      "  valid_dataset = save['valid_dataset']\n",
      "  valid_labels = save['valid_labels']\n",
      "  test_dataset = save['test_dataset']\n",
      "  test_labels = save['test_labels']\n",
      "  del save  # hint to help gc free up memory\n",
      "  print('Training set', train_dataset.shape, train_labels.shape)\n",
      "  print('Validation set', valid_dataset.shape, valid_labels.shape)\n",
      "  print('Test set', test_dataset.shape, test_labels.shape)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Training set (200000, 28, 28) (200000,)\n",
        "Validation set (10000, 28, 28) (10000,)\n",
        "Test set (10000, 28, 28) (10000,)\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "image_size = 28\n",
      "num_labels = 10\n",
      "\n",
      "def reformat(dataset,labels):\n",
      "    dataset = dataset.reshape(-1,image_size*image_size)\n",
      "    zero_labels = np.zeros((len(labels),len(set(labels))))\n",
      "    zero_labels[np.arange(len(labels)),labels] = 1\n",
      "    return dataset,zero_labels\n",
      "train_dataset, train_labels = reformat(train_dataset, train_labels)\n",
      "valid_dataset, valid_labels = reformat(valid_dataset, valid_labels)\n",
      "test_dataset, test_labels = reformat(test_dataset, test_labels)\n",
      "print('Training set', train_dataset.shape, train_labels.shape)\n",
      "print('Validation set', valid_dataset.shape, valid_labels.shape)\n",
      "print('Test set', test_dataset.shape, test_labels.shape)\n",
      "print(train_labels[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Training set (200000, 784) (200000, 10)\n",
        "Validation set (10000, 784) (10000, 10)\n",
        "Test set (10000, 784) (10000, 10)\n",
        "[ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.]\n"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}